{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# CellStrat - Recurrent Neural Networks\n",
    "\n",
    "# Here we develop RNN programs for sequence data processing\n",
    "\n",
    "# Ref : “Hands-on Machine Learning with Scikit-Learn and TensorFlow ” by Aurelien Geron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's make sure this notebook works well in both python 2 and 3, import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/nf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "//anaconda3/envs/nf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "//anaconda3/envs/nf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "//anaconda3/envs/nf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "//anaconda3/envs/nf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "//anaconda3/envs/nf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = '.'\n",
    "CHAPTER_ID = 'rnn'\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, 'images', CHAPTER_ID, fig_id + '.png')\n",
    "    print('Saving figure', fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then of course we will need TensorFlow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CellStrat - lets build an RNN with two time steps, taking input vectors of size 3 at each step.\n",
    "#No of neurons in each cell is 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "Wx = tf.Variable(tf.random_normal(shape=[n_inputs, n_neurons], dtype=tf.float32))\n",
    "Wy = tf.Variable(tf.random_normal(shape=[n_neurons,n_neurons], dtype=tf.float32))\n",
    "b = tf.Variable(tf.zeros([1, n_neurons], dtype=tf.float32))\n",
    "\n",
    "Y0 = tf.tanh(tf.matmul(X0, Wx) + b)\n",
    "Y1 = tf.tanh(tf.matmul(Y0, Wy) + tf.matmul(X1, Wx) + b)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CellStrat - This network looks much like a two-layer feedforward neural network, with a few twists: first, the same\n",
    "#weights and bias terms are shared by both layers, and second, we feed inputs at each layer, and we get\n",
    "#outputs from each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X0_batch = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 0, 1]]) # t = 0\n",
    "X1_batch = np.array([[9, 8, 7], [0, 0, 0], [6, 5, 4], [3, 2, 1]]) # t = 1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict={X0: X0_batch, X1: X1_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.06640061  0.96257669  0.68105787  0.70918542 -0.89821595]\n",
      " [ 0.99777555 -0.71978879 -0.99657613  0.96739244 -0.99989706]\n",
      " [ 0.99999785 -0.99898809 -0.99999887  0.99677628 -0.99999988]\n",
      " [ 1.         -1.         -1.         -0.99818921  0.99950868]]\n"
     ]
    }
   ],
   "source": [
    "print(Y0_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -1.         -1.          0.40200272 -0.99999994]\n",
      " [-0.12210429  0.62805295  0.96718436 -0.99371219 -0.25839329]\n",
      " [ 0.99999815 -0.9999994  -0.99999744 -0.85943311 -0.99998796]\n",
      " [ 0.99928296 -0.99999809 -0.99990588  0.98579615 -0.92205751]]\n"
     ]
    }
   ],
   "source": [
    "print(Y1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `static_rnn()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an RNN of a certain time step length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 3\n",
    "n_neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "output_seqs, states = tf.contrib.rnn.static_rnn(basic_cell, [X0, X1],\n",
    "                                                dtype=tf.float32)\n",
    "Y0, Y1 = output_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0_batch = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 0, 1]])\n",
    "X1_batch = np.array([[9, 8, 7], [0, 0, 0], [6, 5, 4], [3, 2, 1]])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict={X0: X0_batch, X1: X1_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.30741334, -0.32884315, -0.6542847 , -0.9385059 ,  0.52089024],\n",
       "       [ 0.99122757, -0.9542541 , -0.7518079 , -0.9995208 ,  0.9820235 ],\n",
       "       [ 0.9999268 , -0.99783254, -0.8247353 , -0.9999963 ,  0.99947774],\n",
       "       [ 0.996771  , -0.68750614,  0.8419969 ,  0.9303911 ,  0.8120684 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y0_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99998885, -0.99976057, -0.0667929 , -0.9999803 ,  0.99982214],\n",
       "       [-0.6524943 , -0.51520866, -0.37968948, -0.5922594 , -0.08968379],\n",
       "       [ 0.99862397, -0.99715203, -0.03308626, -0.9991566 ,  0.9932902 ],\n",
       "       [ 0.99681675, -0.9598194 ,  0.39660627, -0.8307606 ,  0.79671973]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"b<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.3745401188473625&quot;).pbtxt = 'node {\\n  name: &quot;Placeholder&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Placeholder_1&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;rnn/Shape&quot;\\n  input: &quot;rnn/strided_slice/stack&quot;\\n  input: &quot;rnn/strided_slice/stack_1&quot;\\n  input: &quot;rnn/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/BasicRNNCellZeroState/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/BasicRNNCellZeroState/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;rnn/strided_slice&quot;\\n  input: &quot;rnn/BasicRNNCellZeroState/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/BasicRNNCellZeroState/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 5\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/BasicRNNCellZeroState/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/BasicRNNCellZeroState/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;rnn/BasicRNNCellZeroState/ExpandDims&quot;\\n  input: &quot;rnn/BasicRNNCellZeroState/Const&quot;\\n  input: &quot;rnn/BasicRNNCellZeroState/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/BasicRNNCellZeroState/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/BasicRNNCellZeroState/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;rnn/BasicRNNCellZeroState/concat&quot;\\n  input: &quot;rnn/BasicRNNCellZeroState/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/BasicRNNCellZeroState/ExpandDims_1/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/BasicRNNCellZeroState/ExpandDims_1&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;rnn/strided_slice&quot;\\n  input: &quot;rnn/BasicRNNCellZeroState/ExpandDims_1/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/BasicRNNCellZeroState/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 5\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/basic_rnn_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\010\\\\000\\\\000\\\\000\\\\005\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/basic_rnn_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.6793662309646606\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/basic_rnn_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.6793662309646606\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/basic_rnn_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 20\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/basic_rnn_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/basic_rnn_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/basic_rnn_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/basic_rnn_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 8\\n        }\\n        dim {\\n          size: 5\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;rnn/basic_rnn_cell/kernel&quot;\\n  input: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/basic_rnn_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;rnn/basic_rnn_cell/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/bias/Initializer/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/basic_rnn_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 5\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/bias/Initializer/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/basic_rnn_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/bias/Initializer/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;rnn/basic_rnn_cell/bias/Initializer/zeros/shape_as_tensor&quot;\\n  input: &quot;rnn/basic_rnn_cell/bias/Initializer/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/basic_rnn_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/basic_rnn_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 5\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;rnn/basic_rnn_cell/bias&quot;\\n  input: &quot;rnn/basic_rnn_cell/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/basic_rnn_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;rnn/basic_rnn_cell/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;Placeholder&quot;\\n  input: &quot;rnn/BasicRNNCellZeroState/zeros&quot;\\n  input: &quot;rnn/basic_rnn_cell/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;rnn/basic_rnn_cell/concat&quot;\\n  input: &quot;rnn/basic_rnn_cell/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;rnn/basic_rnn_cell/MatMul&quot;\\n  input: &quot;rnn/basic_rnn_cell/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/Tanh&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;rnn/basic_rnn_cell/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;Placeholder_1&quot;\\n  input: &quot;rnn/basic_rnn_cell/Tanh&quot;\\n  input: &quot;rnn/basic_rnn_cell/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;rnn/basic_rnn_cell/concat_1&quot;\\n  input: &quot;rnn/basic_rnn_cell/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/BiasAdd_1&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;rnn/basic_rnn_cell/MatMul_1&quot;\\n  input: &quot;rnn/basic_rnn_cell/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/Tanh_1&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;rnn/basic_rnn_cell/BiasAdd_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^rnn/basic_rnn_cell/kernel/Assign&quot;\\n  input: &quot;^rnn/basic_rnn_cell/bias/Assign&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.3745401188473625&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packing sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "If there were 50 time steps, it would not be very convenient to have to define 50 input placeholders and 50 output tensors that would be needed in the above code. Moreover, at execution time you would have to feed each of the 50 placeholders and manipulate the 50 outputs. Let’s simplify this. The following code builds the same RNN again, but this time it takes a single input placeholder of shape [None, n_steps, n_inputs] where the first dimension is the mini-batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resets the tf output graph\n",
    "reset_graph()\n",
    "\n",
    "# Input placeholder, of size mini_batch-size*n_steps*n_inputs\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "X_seqs = tf.unstack(tf.transpose(X, perm=[1, 0, 2]))\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "output_seqs, states = tf.contrib.rnn.static_rnn(basic_cell, X_seqs,\n",
    "                                                dtype=tf.float32)\n",
    "outputs = tf.transpose(tf.stack(output_seqs), perm=[1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = np.array([\n",
    "        # t = 0      t = 1 \n",
    "        [[0, 1, 2], [9, 8, 7]], # instance 1\n",
    "        [[3, 4, 5], [0, 0, 0]], # instance 2\n",
    "        [[6, 7, 8], [6, 5, 4]], # instance 3\n",
    "        [[9, 0, 1], [3, 2, 1]], # instance 4\n",
    "    ])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val = outputs.eval(feed_dict={X: X_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.45652324 -0.68064123  0.40938237  0.63104504 -0.45732826]\n",
      "  [-0.9428799  -0.9998869   0.94055814  0.9999985  -0.9999997 ]]\n",
      "\n",
      " [[-0.8001535  -0.9921827   0.7817797   0.9971032  -0.9964609 ]\n",
      "  [-0.637116    0.11300927  0.5798437   0.4310559  -0.6371699 ]]\n",
      "\n",
      " [[-0.93605185 -0.9998379   0.9308867   0.9999815  -0.99998295]\n",
      "  [-0.9165386  -0.9945604   0.896054    0.99987197 -0.9999751 ]]\n",
      "\n",
      " [[ 0.9927369  -0.9981933  -0.55543643  0.9989031  -0.9953323 ]\n",
      "  [-0.02746338 -0.73191994  0.7827872   0.9525682  -0.9781773 ]]]\n"
     ]
    }
   ],
   "source": [
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.45652324 -0.68064123  0.40938237  0.63104504 -0.45732826]\n",
      " [-0.8001535  -0.9921827   0.7817797   0.9971032  -0.9964609 ]\n",
      " [-0.93605185 -0.9998379   0.9308867   0.9999815  -0.99998295]\n",
      " [ 0.9927369  -0.9981933  -0.55543643  0.9989031  -0.9953323 ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(np.transpose(outputs_val, axes=[1, 0, 2])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `dynamic_rnn()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "However, this approach still builds a graph containing one cell per time step. If there were 50 time steps, the graph would look pretty ugly. It is a bit like writing a program without ever using loops (e.g., Y0=f(0, X0); Y1=f(Y0, X1); Y2=f(Y1, X2); ...; Y50=f(Y49, X50)). With such as large graph, you may even get out-of-memory (OOM) errors during backpropagation (especially with the limited memory of GPU cards), since it must store all tensor values during the forward pass so it can use them to compute gradients during the reverse pass.\n",
    "Fortunately, there is a better solution: the dynamic_rnn() function.\n",
    "\n",
    "The dynamic_rnn() function uses a while_loop() operation to run over the cell the appropriate number of times, and you can set swap_memory=True if you want it to swap the GPU’s memory to the CPU’s memory during backpropagation to avoid OOM errors. Conveniently, it also accepts a single tensor for all inputs at every time step (shape [None, n_steps, n_inputs]) and it outputs a single tensor for all outputs at every time step (shape [None, n_steps, n_neurons]); there is no need to stack, unstack, or transpose. The following code creates the same RNN as earlier using the dynamic_rnn() function. It’s so much nicer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = np.array([\n",
    "        [[0, 1, 2], [9, 8, 7]], # instance 1\n",
    "        [[3, 4, 5], [0, 0, 0]], # instance 2\n",
    "        [[6, 7, 8], [6, 5, 4]], # instance 3\n",
    "        [[9, 0, 1], [3, 2, 1]], # instance 4\n",
    "    ])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val = outputs.eval(feed_dict={X: X_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.85115266  0.87358344  0.5802911   0.8954789  -0.0557505 ]\n",
      "  [-0.999996    0.99999577  0.9981815   1.          0.37679607]]\n",
      "\n",
      " [[-0.9983293   0.9992038   0.98071456  0.999985    0.25192663]\n",
      "  [-0.7081804  -0.0772338  -0.85227895  0.5845349  -0.78780943]]\n",
      "\n",
      " [[-0.9999827   0.99999535  0.9992863   1.          0.5159072 ]\n",
      "  [-0.9993956   0.9984095   0.83422637  0.99999976 -0.47325212]]\n",
      "\n",
      " [[ 0.87888587  0.07356028  0.97216916  0.9998546  -0.7351168 ]\n",
      "  [-0.9134514   0.3600957   0.7624866   0.99817705  0.80142   ]]]\n"
     ]
    }
   ],
   "source": [
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.3745401188473625&quot;).pbtxt = 'node {\\n  name: &quot;Placeholder&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 2\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/Rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;rnn/range/start&quot;\\n  input: &quot;rnn/Rank&quot;\\n  input: &quot;rnn/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/concat/values_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;rnn/concat/values_0&quot;\\n  input: &quot;rnn/range&quot;\\n  input: &quot;rnn/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/transpose&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;Placeholder&quot;\\n  input: &quot;rnn/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;rnn/transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;rnn/Shape&quot;\\n  input: &quot;rnn/strided_slice/stack&quot;\\n  input: &quot;rnn/strided_slice/stack_1&quot;\\n  input: &quot;rnn/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/BasicRNNCellZeroState/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/BasicRNNCellZeroState/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;rnn/strided_slice&quot;\\n  input: &quot;rnn/BasicRNNCellZeroState/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/BasicRNNCellZeroState/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 5\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/BasicRNNCellZeroState/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/BasicRNNCellZeroState/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;rnn/BasicRNNCellZeroState/ExpandDims&quot;\\n  input: &quot;rnn/BasicRNNCellZeroState/Const&quot;\\n  input: &quot;rnn/BasicRNNCellZeroState/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/BasicRNNCellZeroState/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/BasicRNNCellZeroState/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;rnn/BasicRNNCellZeroState/concat&quot;\\n  input: &quot;rnn/BasicRNNCellZeroState/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/BasicRNNCellZeroState/ExpandDims_1/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/BasicRNNCellZeroState/ExpandDims_1&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;rnn/strided_slice&quot;\\n  input: &quot;rnn/BasicRNNCellZeroState/ExpandDims_1/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/BasicRNNCellZeroState/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 5\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;rnn/transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/strided_slice_1/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/strided_slice_1/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/strided_slice_1/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/strided_slice_1&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;rnn/Shape_1&quot;\\n  input: &quot;rnn/strided_slice_1/stack&quot;\\n  input: &quot;rnn/strided_slice_1/stack_1&quot;\\n  input: &quot;rnn/strided_slice_1/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;rnn/transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/strided_slice_2/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/strided_slice_2/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/strided_slice_2/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/strided_slice_2&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;rnn/Shape_2&quot;\\n  input: &quot;rnn/strided_slice_2/stack&quot;\\n  input: &quot;rnn/strided_slice_2/stack_1&quot;\\n  input: &quot;rnn/strided_slice_2/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;rnn/strided_slice_2&quot;\\n  input: &quot;rnn/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 5\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;rnn/ExpandDims&quot;\\n  input: &quot;rnn/Const&quot;\\n  input: &quot;rnn/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;rnn/concat_1&quot;\\n  input: &quot;rnn/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/time&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/TensorArray&quot;\\n  op: &quot;TensorArrayV3&quot;\\n  input: &quot;rnn/strided_slice_1&quot;\\n  attr {\\n    key: &quot;clear_after_read&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;dynamic_size&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 5\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;identical_element_shapes&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;tensor_array_name&quot;\\n    value {\\n      s: &quot;rnn/dynamic_rnn/output_0&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/TensorArray_1&quot;\\n  op: &quot;TensorArrayV3&quot;\\n  input: &quot;rnn/strided_slice_1&quot;\\n  attr {\\n    key: &quot;clear_after_read&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;dynamic_size&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;identical_element_shapes&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;tensor_array_name&quot;\\n    value {\\n      s: &quot;rnn/dynamic_rnn/input_0&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/TensorArrayUnstack/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;rnn/transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/TensorArrayUnstack/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/TensorArrayUnstack/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/TensorArrayUnstack/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/TensorArrayUnstack/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;rnn/TensorArrayUnstack/Shape&quot;\\n  input: &quot;rnn/TensorArrayUnstack/strided_slice/stack&quot;\\n  input: &quot;rnn/TensorArrayUnstack/strided_slice/stack_1&quot;\\n  input: &quot;rnn/TensorArrayUnstack/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/TensorArrayUnstack/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/TensorArrayUnstack/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/TensorArrayUnstack/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;rnn/TensorArrayUnstack/range/start&quot;\\n  input: &quot;rnn/TensorArrayUnstack/strided_slice&quot;\\n  input: &quot;rnn/TensorArrayUnstack/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  op: &quot;TensorArrayScatterV3&quot;\\n  input: &quot;rnn/TensorArray_1&quot;\\n  input: &quot;rnn/TensorArrayUnstack/range&quot;\\n  input: &quot;rnn/transpose&quot;\\n  input: &quot;rnn/TensorArray_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/transpose&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/Maximum/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;rnn/Maximum/x&quot;\\n  input: &quot;rnn/strided_slice_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;rnn/strided_slice_1&quot;\\n  input: &quot;rnn/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/iteration_counter&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;rnn/while/iteration_counter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;rnn/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;rnn/time&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;rnn/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/Enter_2&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;rnn/TensorArray:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;rnn/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/Enter_3&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;rnn/BasicRNNCellZeroState/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;rnn/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;rnn/while/Enter&quot;\\n  input: &quot;rnn/while/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/Merge_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;rnn/while/Enter_1&quot;\\n  input: &quot;rnn/while/NextIteration_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/Merge_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;rnn/while/Enter_2&quot;\\n  input: &quot;rnn/while/NextIteration_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/Merge_3&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;rnn/while/Enter_3&quot;\\n  input: &quot;rnn/while/NextIteration_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/Less&quot;\\n  op: &quot;Less&quot;\\n  input: &quot;rnn/while/Merge&quot;\\n  input: &quot;rnn/while/Less/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/Less/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;rnn/strided_slice_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;rnn/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/Less_1&quot;\\n  op: &quot;Less&quot;\\n  input: &quot;rnn/while/Merge_1&quot;\\n  input: &quot;rnn/while/Less_1/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/Less_1/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;rnn/Minimum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;rnn/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/LogicalAnd&quot;\\n  op: &quot;LogicalAnd&quot;\\n  input: &quot;rnn/while/Less&quot;\\n  input: &quot;rnn/while/Less_1&quot;\\n}\\nnode {\\n  name: &quot;rnn/while/LoopCond&quot;\\n  op: &quot;LoopCond&quot;\\n  input: &quot;rnn/while/LogicalAnd&quot;\\n}\\nnode {\\n  name: &quot;rnn/while/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;rnn/while/Merge&quot;\\n  input: &quot;rnn/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/while/Merge&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;rnn/while/Merge_1&quot;\\n  input: &quot;rnn/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/while/Merge_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;rnn/while/Merge_2&quot;\\n  input: &quot;rnn/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/while/Merge_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/Switch_3&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;rnn/while/Merge_3&quot;\\n  input: &quot;rnn/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/while/Merge_3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/Identity&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;rnn/while/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/Identity_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;rnn/while/Switch_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/Identity_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;rnn/while/Switch_2:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/Identity_3&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;rnn/while/Switch_3:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^rnn/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;rnn/while/Identity&quot;\\n  input: &quot;rnn/while/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/TensorArrayReadV3&quot;\\n  op: &quot;TensorArrayReadV3&quot;\\n  input: &quot;rnn/while/TensorArrayReadV3/Enter&quot;\\n  input: &quot;rnn/while/Identity_1&quot;\\n  input: &quot;rnn/while/TensorArrayReadV3/Enter_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/TensorArrayReadV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;rnn/TensorArray_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;rnn/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/TensorArrayReadV3/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;rnn/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;rnn/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/basic_rnn_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\010\\\\000\\\\000\\\\000\\\\005\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/basic_rnn_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.6793662309646606\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/basic_rnn_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.6793662309646606\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/basic_rnn_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 87\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/basic_rnn_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/basic_rnn_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/basic_rnn_cell/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/basic_rnn_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 8\\n        }\\n        dim {\\n          size: 5\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;rnn/basic_rnn_cell/kernel&quot;\\n  input: &quot;rnn/basic_rnn_cell/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/basic_rnn_cell/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;rnn/basic_rnn_cell/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/bias/Initializer/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/basic_rnn_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 5\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/bias/Initializer/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/basic_rnn_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/bias/Initializer/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;rnn/basic_rnn_cell/bias/Initializer/zeros/shape_as_tensor&quot;\\n  input: &quot;rnn/basic_rnn_cell/bias/Initializer/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/basic_rnn_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/basic_rnn_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 5\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;rnn/basic_rnn_cell/bias&quot;\\n  input: &quot;rnn/basic_rnn_cell/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/basic_rnn_cell/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/basic_rnn_cell/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;rnn/basic_rnn_cell/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/basic_rnn_cell/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^rnn/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/basic_rnn_cell/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;rnn/while/TensorArrayReadV3&quot;\\n  input: &quot;rnn/while/Identity_3&quot;\\n  input: &quot;rnn/while/basic_rnn_cell/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/basic_rnn_cell/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;rnn/while/basic_rnn_cell/concat&quot;\\n  input: &quot;rnn/while/basic_rnn_cell/MatMul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/basic_rnn_cell/MatMul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;rnn/basic_rnn_cell/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;rnn/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/basic_rnn_cell/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;rnn/while/basic_rnn_cell/MatMul&quot;\\n  input: &quot;rnn/while/basic_rnn_cell/BiasAdd/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/basic_rnn_cell/BiasAdd/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;rnn/basic_rnn_cell/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;rnn/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/basic_rnn_cell/Tanh&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;rnn/while/basic_rnn_cell/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  op: &quot;TensorArrayWriteV3&quot;\\n  input: &quot;rnn/while/TensorArrayWrite/TensorArrayWriteV3/Enter&quot;\\n  input: &quot;rnn/while/Identity_1&quot;\\n  input: &quot;rnn/while/basic_rnn_cell/Tanh&quot;\\n  input: &quot;rnn/while/Identity_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/while/basic_rnn_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/TensorArrayWrite/TensorArrayWriteV3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;rnn/TensorArray&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/while/basic_rnn_cell/Tanh&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;rnn/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/add_1/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^rnn/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;rnn/while/Identity_1&quot;\\n  input: &quot;rnn/while/add_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;rnn/while/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/NextIteration_1&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;rnn/while/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/NextIteration_2&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;rnn/while/TensorArrayWrite/TensorArrayWriteV3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/NextIteration_3&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;rnn/while/basic_rnn_cell/Tanh&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;rnn/while/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/Exit_1&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;rnn/while/Switch_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/Exit_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;rnn/while/Switch_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/while/Exit_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;rnn/while/Switch_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/TensorArrayStack/TensorArraySizeV3&quot;\\n  op: &quot;TensorArraySizeV3&quot;\\n  input: &quot;rnn/TensorArray&quot;\\n  input: &quot;rnn/while/Exit_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/TensorArrayStack/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/TensorArrayStack/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/TensorArrayStack/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;rnn/TensorArrayStack/range/start&quot;\\n  input: &quot;rnn/TensorArrayStack/TensorArraySizeV3&quot;\\n  input: &quot;rnn/TensorArrayStack/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/TensorArray&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/TensorArrayStack/TensorArrayGatherV3&quot;\\n  op: &quot;TensorArrayGatherV3&quot;\\n  input: &quot;rnn/TensorArray&quot;\\n  input: &quot;rnn/TensorArrayStack/range&quot;\\n  input: &quot;rnn/while/Exit_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@rnn/TensorArray&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;element_shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 5\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 5\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/Rank_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/range_1/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/range_1/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/range_1&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;rnn/range_1/start&quot;\\n  input: &quot;rnn/Rank_1&quot;\\n  input: &quot;rnn/range_1/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/concat_2/values_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/concat_2/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/concat_2&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;rnn/concat_2/values_0&quot;\\n  input: &quot;rnn/range_1&quot;\\n  input: &quot;rnn/concat_2/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;rnn/transpose_1&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;rnn/TensorArrayStack/TensorArrayGatherV3&quot;\\n  input: &quot;rnn/concat_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^rnn/basic_rnn_cell/kernel/Assign&quot;\\n  input: &quot;^rnn/basic_rnn_cell/bias/Assign&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.3745401188473625&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the sequence lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "So far we had fixed length sequences (precisely 2 time steps actually) now lets see how to handle variable length sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = tf.placeholder(tf.int32, [None])\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32,\n",
    "                                    sequence_length=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = np.array([\n",
    "        # step 0     step 1\n",
    "        [[0, 1, 2], [9, 8, 7]], # instance 1\n",
    "        [[3, 4, 5], [0, 0, 0]], # instance 2 (padded with zero vectors)\n",
    "        [[6, 7, 8], [6, 5, 4]], # instance 3\n",
    "        [[9, 0, 1], [3, 2, 1]], # instance 4\n",
    "    ])\n",
    "seq_length_batch = np.array([2, 1, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val, states_val = sess.run(\n",
    "        [outputs, states], feed_dict={X: X_batch, seq_length: seq_length_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.04335004 -0.79070514  0.62847096 -0.16162856  0.82851917]\n",
      "  [-0.23427285 -0.98320025  1.          0.05531171  0.13038827]]\n",
      "\n",
      " [[ 0.06481664 -0.98885173  0.99938971 -0.28373343  0.94707841]\n",
      "  [ 0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.08622331 -0.99946249  0.99999917 -0.39728165  0.98436832]\n",
      "  [-0.39562979 -0.49045306  0.99999106  0.26839554 -0.66423559]]\n",
      "\n",
      " [[-0.9948616   0.99336129  0.99999344  0.90489864 -0.99997765]\n",
      "  [ 0.65352571 -0.56341326  0.99020582  0.72314978  0.30071682]]]\n"
     ]
    }
   ],
   "source": [
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.23427285 -0.98320025  1.          0.05531171  0.13038827]\n",
      " [ 0.06481664 -0.98885173  0.99938971 -0.28373343  0.94707841]\n",
      " [-0.39562979 -0.49045306  0.99999106  0.26839554 -0.66423559]\n",
      " [ 0.65352571 -0.56341326  0.99020582  0.72314978  0.30071682]]\n"
     ]
    }
   ],
   "source": [
    "print(states_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a sequence classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Train an RNN to classify MNIST images. Normally CNNs are better for this task, but we try with RNN here. Connect a fully connected softmax layer after last time step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the book uses `tensorflow.contrib.layers.fully_connected()` rather than `tf.layers.dense()` (which did not exist when this chapter was written). It is now preferable to use `tf.layers.dense()`, because anything in the contrib module may change or be deleted without notice. The `dense()` function is almost identical to the `fully_connected()` function. The main differences relevant to this chapter are:\n",
    "* several parameters are renamed: `scope` becomes `name`, `activation_fn` becomes `activation` (and similarly the `_fn` suffix is removed from other parameters such as `normalizer_fn`), `weights_initializer` becomes `kernel_initializer`, etc.\n",
    "* the default `activation` is now `None` rather than `tf.nn.relu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_steps = 28\n",
    "n_inputs = 28\n",
    "n_neurons = 150\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)\n",
    "\n",
    "logits = tf.layers.dense(states, n_outputs)\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                          logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('/tmp/data/')\n",
    "X_test = mnist.test.images.reshape((-1, n_steps, n_inputs))\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Train accuracy: 0.93, Test accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            X_batch = X_batch.reshape((-1, n_steps, n_inputs))\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print(f'Epoch [{epoch+1}/{n_epochs}], Train accuracy: {acc_train:.2f}, Test accuracy: {acc_test:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Lets train a Deep RNN with 3 layers. Use it to train an MNIST classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_steps = 28\n",
    "n_inputs = 28\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neurons = 100\n",
    "n_layers = 3\n",
    "\n",
    "# List containing the three layers\n",
    "layers = [tf.contrib.rnn.BasicRNNCell(num_units=n_neurons,\n",
    "                                      activation=tf.nn.relu)\n",
    "          for layer in range(n_layers)]\n",
    "\n",
    "# Combine to a multilayer rnn cell\n",
    "multi_layer_cell = tf.contrib.rnn.MultiRNNCell(layers)\n",
    "\n",
    "# Use dynamic_rnn to run over the cell the appropriate number of times, \n",
    "outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_concat = tf.concat(axis=1, values=states)\n",
    "logits = tf.layers.dense(states_concat, n_outputs)\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Train accuracy: 0.97, Test accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            X_batch = X_batch.reshape((-1, n_steps, n_inputs))\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print(f'Epoch [{epoch+1}/{n_epochs}], Train accuracy: {acc_train:.2f}, Test accuracy: {acc_test:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "We will train an RNN to predict the next value in a generated time series. Each training instance is a randomly selected sequence of 20 consecutive values from the time series, and the target sequence is the same as the input sequence, except it is shifted by one time step into the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_min, t_max = 0, 30\n",
    "resolution = 0.1\n",
    "\n",
    "def time_series(t):\n",
    "    return t * np.sin(t) / 3 + 2 * np.sin(t*5)\n",
    "\n",
    "def next_batch(batch_size, n_steps):\n",
    "    t0 = np.random.rand(batch_size, 1) * (t_max - t_min - n_steps * resolution)\n",
    "    Ts = t0 + np.arange(0., n_steps + 1) * resolution\n",
    "    ys = time_series(Ts)\n",
    "    return ys[:, :-1].reshape(-1, n_steps, 1), ys[:, 1:].reshape(-1, n_steps, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure time_series_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = np.linspace(t_min, t_max, int((t_max - t_min) / resolution))\n",
    "\n",
    "n_steps = 20\n",
    "t_instance = np.linspace(12.2, 12.2 + resolution * (n_steps + 1), n_steps + 1)\n",
    "\n",
    "plt.figure(figsize=(11, 4))\n",
    "plt.subplot(121)\n",
    "plt.title(\"A time series (generated)\", fontsize=14)\n",
    "plt.plot(t, time_series(t), label=r\"$t . \\sin(t) / 3 + 2 . \\sin(5t)$\")\n",
    "plt.plot(t_instance[:-1], time_series(t_instance[:-1]), \"b-\", linewidth=3, label=\"A training instance\")\n",
    "plt.legend(loc=\"lower left\", fontsize=14)\n",
    "plt.axis([0, 30, -17, 13])\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Value\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title(\"A training instance\", fontsize=14)\n",
    "plt.plot(t_instance[:-1], time_series(t_instance[:-1]), \"bo\", markersize=10, label=\"instance\")\n",
    "plt.plot(t_instance[1:], time_series(t_instance[1:]), \"w*\", markersize=10, label=\"target\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel(\"Time\")\n",
    "\n",
    "\n",
    "save_fig(\"time_series_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch, y_batch = next_batch(1, n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.22465526, -1.52591893],\n",
       "       [-1.52591893, -0.96401095],\n",
       "       [-0.96401095, -0.73998176],\n",
       "       [-0.73998176, -0.96752099],\n",
       "       [-0.96752099, -1.64441782],\n",
       "       [-1.64441782, -2.65244138],\n",
       "       [-2.65244138, -3.78567831],\n",
       "       [-3.78567831, -4.80039693],\n",
       "       [-4.80039693, -5.47423643],\n",
       "       [-5.47423643, -5.66023585],\n",
       "       [-5.66023585, -5.32248022],\n",
       "       [-5.32248022, -4.54464151],\n",
       "       [-4.54464151, -3.50932718],\n",
       "       [-3.50932718, -2.45329587],\n",
       "       [-2.45329587, -1.60950713],\n",
       "       [-1.60950713, -1.15019496],\n",
       "       [-1.15019496, -1.14490296],\n",
       "       [-1.14490296, -1.54375498],\n",
       "       [-1.54375498, -2.19005543],\n",
       "       [-2.19005543, -2.85913179]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.c_[X_batch[0], y_batch[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using an `OuputProjectionWrapper`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the RNN. It will contain 100 recurrent neurons and we will unroll it over 20 time steps since each traiing instance will be 20 inputs long. Each input will contain only one feature (the value at that time). The targets are also sequences of 20 inputs, each containing a sigle value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_steps = 20\n",
    "n_inputs = 1\n",
    "n_neurons = 100\n",
    "n_outputs = 1\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])\n",
    "\n",
    "cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons, activation=tf.nn.relu)\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At each time step we now have an output vector of size 100. But what we actually want is a single output value at each time step. The simplest solution is to wrap the cell in an `OutputProjectionWrapper`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_steps = 20\n",
    "n_inputs = 1\n",
    "n_neurons = 100\n",
    "n_outputs = 1\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = tf.contrib.rnn.OutputProjectionWrapper(\n",
    "    tf.contrib.rnn.BasicRNNCell(num_units=n_neurons, activation=tf.nn.relu),\n",
    "    output_size=n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(outputs - y)) # MSE\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \tMSE: 11.234554\n",
      "100 \tMSE: 0.38021222\n",
      "200 \tMSE: 0.12111042\n",
      "300 \tMSE: 0.064446695\n",
      "400 \tMSE: 0.05852244\n",
      "500 \tMSE: 0.05630867\n",
      "600 \tMSE: 0.050434463\n",
      "700 \tMSE: 0.045523368\n",
      "800 \tMSE: 0.048774377\n",
      "900 \tMSE: 0.04667491\n",
      "1000 \tMSE: 0.04696534\n",
      "1100 \tMSE: 0.045852553\n",
      "1200 \tMSE: 0.039650373\n",
      "1300 \tMSE: 0.047102667\n",
      "1400 \tMSE: 0.040489137\n"
     ]
    }
   ],
   "source": [
    "n_iterations = 1500\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for iteration in range(n_iterations):\n",
    "        X_batch, y_batch = next_batch(batch_size, n_steps)\n",
    "        sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if iteration % 100 == 0:\n",
    "            mse = loss.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            print(iteration, \"\\tMSE:\", mse)\n",
    "    \n",
    "    saver.save(sess, \"./my_time_series_model\") # not shown in the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_time_series_model\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:                          # not shown in the content\n",
    "    saver.restore(sess, \"./my_time_series_model\")   # not shown\n",
    "\n",
    "    X_new = time_series(np.array(t_instance[:-1].reshape(-1, n_steps, n_inputs)))\n",
    "    y_pred = sess.run(outputs, feed_dict={X: X_new})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-3.3839061 ],\n",
       "        [-2.44384   ],\n",
       "        [-1.159047  ],\n",
       "        [ 0.70688784],\n",
       "        [ 2.177589  ],\n",
       "        [ 3.0767996 ],\n",
       "        [ 3.4366379 ],\n",
       "        [ 3.3269014 ],\n",
       "        [ 2.833223  ],\n",
       "        [ 2.1952014 ],\n",
       "        [ 1.6940963 ],\n",
       "        [ 1.5705847 ],\n",
       "        [ 1.9272693 ],\n",
       "        [ 2.718801  ],\n",
       "        [ 3.8731227 ],\n",
       "        [ 5.089126  ],\n",
       "        [ 6.1004977 ],\n",
       "        [ 6.642303  ],\n",
       "        [ 6.62379   ],\n",
       "        [ 6.0604224 ]]], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure time_series_pred_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Testing the model\", fontsize=14)\n",
    "plt.plot(t_instance[:-1], time_series(t_instance[:-1]), \"bo\", markersize=10, label=\"instance\")\n",
    "plt.plot(t_instance[1:], time_series(t_instance[1:]), \"w*\", markersize=10, label=\"target\")\n",
    "plt.plot(t_instance[1:], y_pred[0,:,0], \"r.\", markersize=10, label=\"prediction\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel(\"Time\")\n",
    "\n",
    "save_fig(\"time_series_pred_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiRNNCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 2\n",
    "n_steps = 5\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "n_neurons = 100\n",
    "n_layers = 3\n",
    "\n",
    "layers = [tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "          for layer in range(n_layers)]\n",
    "multi_layer_cell = tf.contrib.rnn.MultiRNNCell(layers)\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X_batch = np.random.rand(2, n_steps, n_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val, states_val = sess.run([outputs, states], feed_dict={X: X_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#If you build a very deep RNN, it may end up overfitting the training set. To prevent that, a common\n",
    "#technique is to apply dropout. One can simply add a dropout layer before or\n",
    "#after the RNN as usual, but if one also wants to apply dropout between the RNN layers, one needs to use a\n",
    "#DropoutWrapper. The following code applies dropout to the inputs of each layer in the RNN, dropping\n",
    "#each input with a 50% probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 1\n",
    "n_neurons = 100\n",
    "n_layers = 3\n",
    "n_steps = 20\n",
    "n_outputs = 1\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "keep_prob = 0.5\n",
    "\n",
    "cells = [tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "         for layer in range(n_layers)]\n",
    "cells_drop = [tf.contrib.rnn.DropoutWrapper(cell, input_keep_prob=keep_prob)\n",
    "              for cell in cells]\n",
    "multi_layer_cell = tf.contrib.rnn.MultiRNNCell(cells_drop)\n",
    "rnn_outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons])\n",
    "stacked_outputs = tf.layers.dense(stacked_rnn_outputs, n_outputs)\n",
    "outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs])\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(outputs - y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, this code is only usable for training, because the `DropoutWrapper` class has no `training` parameter, so it always applies dropout, even when the model is not being trained, so we must first train the model, then create a different model for testing, without the `DropoutWrapper`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations = 1000\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for iteration in range(n_iterations):\n",
    "        X_batch, y_batch = next_batch(batch_size, n_steps)\n",
    "        _, mse = sess.run([training_op, loss], feed_dict={X: X_batch, y: y_batch})\n",
    "        if iteration % 100 == 0:\n",
    "            print(iteration, \"Training MSE:\", mse)\n",
    "    \n",
    "    saver.save(sess, \"./my_dropout_time_series_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is trained, we need to create the model again, but without the `DropoutWrapper` for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 1\n",
    "n_neurons = 100\n",
    "n_layers = 3\n",
    "n_steps = 20\n",
    "n_outputs = 1\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])\n",
    "\n",
    "keep_prob = 0.5\n",
    "\n",
    "cells = [tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "         for layer in range(n_layers)]\n",
    "multi_layer_cell = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "rnn_outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons])\n",
    "stacked_outputs = tf.layers.dense(stacked_rnn_outputs, n_outputs)\n",
    "outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs])\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(outputs - y))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_dropout_time_series_model\")\n",
    "\n",
    "    X_new = time_series(np.array(t_instance[:-1].reshape(-1, n_steps, n_inputs)))\n",
    "    y_pred = sess.run(outputs, feed_dict={X: X_new})\n",
    "\n",
    "plt.title(\"Testing the model\", fontsize=14)\n",
    "plt.plot(t_instance[:-1], time_series(t_instance[:-1]), \"bo\", markersize=10, label=\"instance\")\n",
    "plt.plot(t_instance[1:], time_series(t_instance[1:]), \"w*\", markersize=10, label=\"target\")\n",
    "plt.plot(t_instance[1:], y_pred[0,:,0], \"r.\", markersize=10, label=\"prediction\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel(\"Time\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops, it seems that Dropout does not help at all in this particular case. :/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to write a script with a command line argument to specify whether you want to train the mode or use it for making predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "import sys\n",
    "training = True  # in a script, this would be (sys.argv[-1] == \"train\") instead\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])\n",
    "\n",
    "cells = [tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "         for layer in range(n_layers)]\n",
    "if training:\n",
    "    cells = [tf.contrib.rnn.DropoutWrapper(cell, input_keep_prob=keep_prob)\n",
    "             for cell in cells]\n",
    "multi_layer_cell = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "rnn_outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)\n",
    "\n",
    "stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons])    # not shown in the content\n",
    "stacked_outputs = tf.layers.dense(stacked_rnn_outputs, n_outputs) # not shown\n",
    "outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs])   # not shown\n",
    "loss = tf.reduce_mean(tf.square(outputs - y))                     # not shown\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)   # not shown\n",
    "training_op = optimizer.minimize(loss)                            # not shown\n",
    "init = tf.global_variables_initializer()                          # not shown\n",
    "saver = tf.train.Saver()                                          # not shown\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if training:\n",
    "        init.run()\n",
    "        for iteration in range(n_iterations):\n",
    "            X_batch, y_batch = next_batch(batch_size, n_steps)    # not shown\n",
    "            _, mse = sess.run([training_op, loss], feed_dict={X: X_batch, y: y_batch}) # not shown\n",
    "            if iteration % 100 == 0:                              # not shown\n",
    "                print(iteration, \"Training MSE:\", mse)            # not shown\n",
    "        save_path = saver.save(sess, \"/tmp/my_model.ckpt\")\n",
    "    else:\n",
    "        saver.restore(sess, \"/tmp/my_model.ckpt\")\n",
    "        X_new = time_series(np.array(t_instance[:-1].reshape(-1, n_steps, n_inputs))) # not shown\n",
    "        y_pred = sess.run(outputs, feed_dict={X: X_new})                              # not shown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "lstm_cell = tf.contrib.rnn.BasicLSTMCell(num_units=n_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 28\n",
    "n_inputs = 28\n",
    "n_neurons = 150\n",
    "n_outputs = 10\n",
    "n_layers = 3\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "lstm_cells = [tf.contrib.rnn.BasicLSTMCell(num_units=n_neurons)\n",
    "              for layer in range(n_layers)]\n",
    "multi_cell = tf.contrib.rnn.MultiRNNCell(lstm_cells)\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_cell, X, dtype=tf.float32)\n",
    "top_layer_h_state = states[-1][1]\n",
    "logits = tf.layers.dense(top_layer_h_state, n_outputs, name=\"softmax\")\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_layer_h_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            X_batch = X_batch.reshape((batch_size, n_steps, n_inputs))\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print(\"Epoch\", epoch, \"Train accuracy =\", acc_train, \"Test accuracy =\", acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "lstm_cell = tf.contrib.rnn.LSTMCell(num_units=n_neurons, use_peepholes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "gru_cell = tf.contrib.rnn.GRUCell(num_units=n_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#CellStrat - Let's look at Natural Language Processing applications, most of which use RNN now.\n",
    "\n",
    "#NOTE :- OPTIONAL MATERIAL\n",
    "#IT IS ENOUGH TO JUST REVIEW THE FOLLOWING CODE ON HIGH LEVEL. UNDERSTANDING THIS CODE IN DETAIL IS OUT OF SCOPE\n",
    "#OF THIS COURSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is based on TensorFlow's [Word2Vec tutorial](https://www.tensorflow.org/versions/r0.11/tutorials/word2vec/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import urllib\n",
    "\n",
    "import errno\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "WORDS_PATH = \"datasets/words\"\n",
    "WORDS_URL = 'http://mattmahoney.net/dc/text8.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_p(path):\n",
    "    \"\"\"Create directories, ok if they already exist.\n",
    "    \n",
    "    This is for python 2 support. In python >=3.2, simply use:\n",
    "    >>> os.makedirs(path, exist_ok=True)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "def fetch_words_data(words_url=WORDS_URL, words_path=WORDS_PATH):\n",
    "    os.makedirs(words_path, exist_ok=True)\n",
    "    zip_path = os.path.join(words_path, \"words.zip\")\n",
    "    if not os.path.exists(zip_path):\n",
    "        urllib.request.urlretrieve(words_url, zip_path)\n",
    "    with zipfile.ZipFile(zip_path) as f:\n",
    "        data = f.read(f.namelist()[0])\n",
    "    return data.decode(\"ascii\").split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = fetch_words_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anarchism', 'originated', 'as', 'a', 'term']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "vocabulary_size = 50000\n",
    "\n",
    "vocabulary = [(\"UNK\", None)] + Counter(words).most_common(vocabulary_size - 1)\n",
    "vocabulary = np.array([word for word, _ in vocabulary])\n",
    "dictionary = {word: code for code, word in enumerate(vocabulary)}\n",
    "data = np.array([dictionary.get(word, 0) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('anarchism originated as a term of abuse first used',\n",
       " array([5234, 3081,   12,    6,  195,    2, 3134,   46,   59]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(words[:9]), data[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cycles originated as a term of abuse first used'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([vocabulary[word_index] for word_index in [5241, 3081, 12, 6, 195, 2, 3134, 46, 59]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('culottes', 0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[24], data[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = ['good', 'good', 'morning', 'america']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = Counter(lis).most_common(2)\n",
    "cnt = np.array([w for w, _ in cnt])\n",
    "cnt_d = {word: code for code, word in enumerate(cnt)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([cnt_d.get(word, 0) for word in lis])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import deque\n",
    "\n",
    "def generate_batch(batch_size, num_skips, skip_window):\n",
    "    global data_index\n",
    "    assert batch_size % num_skips == 0\n",
    "    assert num_skips <= 2 * skip_window\n",
    "    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "    labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "    span = 2 * skip_window + 1 # [ skip_window target skip_window ]\n",
    "    buffer = deque(maxlen=span)\n",
    "    for _ in range(span):\n",
    "        buffer.append(data[data_index])\n",
    "        data_index = (data_index + 1) % len(data)\n",
    "    for i in range(batch_size // num_skips):\n",
    "        target = skip_window  # target label at the center of the buffer\n",
    "        targets_to_avoid = [ skip_window ]\n",
    "        for j in range(num_skips):\n",
    "            while target in targets_to_avoid:\n",
    "                target = random.randint(0, span - 1)\n",
    "            targets_to_avoid.append(target)\n",
    "            batch[i * num_skips + j] = buffer[skip_window]\n",
    "            labels[i * num_skips + j, 0] = buffer[target]\n",
    "        buffer.append(data[data_index])\n",
    "        data_index = (data_index + 1) % len(data)\n",
    "    return batch, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data_index=0\n",
    "batch, labels = generate_batch(8, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, [vocabulary[word] for word in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, [vocabulary[word] for word in labels[:, 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "embedding_size = 128  # Dimension of the embedding vector.\n",
    "skip_window = 1       # How many words to consider left and right.\n",
    "num_skips = 2         # How many times to reuse an input to generate a label.\n",
    "\n",
    "# We pick a random validation set to sample nearest neighbors. Here we limit the\n",
    "# validation samples to the words that have a low numeric ID, which by\n",
    "# construction are also the most frequent.\n",
    "valid_size = 16     # Random set of words to evaluate similarity on.\n",
    "valid_window = 100  # Only pick dev samples in the head of the distribution.\n",
    "valid_examples = np.random.choice(valid_window, valid_size, replace=False)\n",
    "num_sampled = 64    # Number of negative examples to sample.\n",
    "\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "# Input data.\n",
    "train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "valid_dataset = tf.constant(valid_examples, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 50000\n",
    "embedding_size = 150\n",
    "\n",
    "# Look up embeddings for inputs.\n",
    "init_embeds = tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0)\n",
    "embeddings = tf.Variable(init_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_inputs = tf.placeholder(tf.int32, shape=[None])\n",
    "embed = tf.nn.embedding_lookup(embeddings, train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#CellStrat - NCE is explained here :-\n",
    "#https://datascience.stackexchange.com/questions/13216/intuitive-explanation-of-noise-contrastive-estimation-nce-loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Construct the variables for the NCE loss\n",
    "nce_weights = tf.Variable(\n",
    "    tf.truncated_normal([vocabulary_size, embedding_size],\n",
    "                        stddev=1.0 / np.sqrt(embedding_size)))\n",
    "nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "\n",
    "# Compute the average NCE loss for the batch.\n",
    "# tf.nce_loss automatically draws a new sample of the negative labels each\n",
    "# time we evaluate the loss.\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.nce_loss(nce_weights, nce_biases, train_labels, embed,\n",
    "                   num_sampled, vocabulary_size))\n",
    "\n",
    "# Construct the Adam optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "# Compute the cosine similarity between minibatch examples and all embeddings.\n",
    "norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), axis=1, keep_dims=True))\n",
    "normalized_embeddings = embeddings / norm\n",
    "valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, valid_dataset)\n",
    "similarity = tf.matmul(valid_embeddings, normalized_embeddings, transpose_b=True)\n",
    "\n",
    "# Add variable initializer.\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 10001\n",
    "\n",
    "with tf.Session() as session:\n",
    "    init.run()\n",
    "\n",
    "    average_loss = 0\n",
    "    for step in range(num_steps):\n",
    "        print(\"\\rIteration: {}\".format(step), end=\"\\t\")\n",
    "        batch_inputs, batch_labels = generate_batch(batch_size, num_skips, skip_window)\n",
    "        feed_dict = {train_inputs : batch_inputs, train_labels : batch_labels}\n",
    "\n",
    "        # We perform one update step by evaluating the training op (including it\n",
    "        # in the list of returned values for session.run()\n",
    "        _, loss_val = session.run([training_op, loss], feed_dict=feed_dict)\n",
    "        average_loss += loss_val\n",
    "\n",
    "        if step % 2000 == 0:\n",
    "            if step > 0:\n",
    "                average_loss /= 2000\n",
    "            # The average loss is an estimate of the loss over the last 2000 batches.\n",
    "            print(\"Average loss at step \", step, \": \", average_loss)\n",
    "            average_loss = 0\n",
    "\n",
    "        # Note that this is expensive (~20% slowdown if computed every 500 steps)\n",
    "        if step % 10000 == 0:\n",
    "            sim = similarity.eval()\n",
    "            for i in range(valid_size):\n",
    "                valid_word = vocabulary[valid_examples[i]]\n",
    "                top_k = 8 # number of nearest neighbors\n",
    "                nearest = (-sim[i, :]).argsort()[1:top_k+1]\n",
    "                log_str = \"Nearest to %s:\" % valid_word\n",
    "                for k in range(top_k):\n",
    "                    close_word = vocabulary[nearest[k]]\n",
    "                    log_str = \"%s %s,\" % (log_str, close_word)\n",
    "                print(log_str)\n",
    "\n",
    "    final_embeddings = normalized_embeddings.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the final embeddings (of course you can use a TensorFlow `Saver` if you prefer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "np.save(\"./my_final_embeddings.npy\", final_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_with_labels(low_dim_embs, labels):\n",
    "    assert low_dim_embs.shape[0] >= len(labels), \"More labels than embeddings\"\n",
    "    plt.figure(figsize=(18, 18))  #in inches\n",
    "    for i, label in enumerate(labels):\n",
    "        x, y = low_dim_embs[i,:]\n",
    "        plt.scatter(x, y)\n",
    "        plt.annotate(label,\n",
    "                     xy=(x, y),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "plot_only = 500\n",
    "low_dim_embs = tsne.fit_transform(final_embeddings[:plot_only,:])\n",
    "labels = [vocabulary[i] for i in range(plot_only)]\n",
    "plot_with_labels(low_dim_embs, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `basic_rnn_seq2seq()` function creates a simple Encoder/Decoder model: it first runs an RNN to encode `encoder_inputs` into a state vector, then runs a decoder initialized with the last encoder state on `decoder_inputs`. Encoder and decoder use the same RNN cell type but they don't share parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "reset_graph()\n",
    "\n",
    "n_steps = 50\n",
    "n_neurons = 200\n",
    "n_layers = 3\n",
    "num_encoder_symbols = 20000\n",
    "num_decoder_symbols = 20000\n",
    "embedding_size = 150\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.int32, [None, n_steps]) # English sentences\n",
    "Y = tf.placeholder(tf.int32, [None, n_steps]) # French translations\n",
    "W = tf.placeholder(tf.float32, [None, n_steps - 1, 1])\n",
    "Y_input = Y[:, :-1]\n",
    "Y_target = Y[:, 1:]\n",
    "\n",
    "encoder_inputs = tf.unstack(tf.transpose(X)) # list of 1D tensors\n",
    "decoder_inputs = tf.unstack(tf.transpose(Y_input)) # list of 1D tensors\n",
    "\n",
    "lstm_cells = [tf.contrib.rnn.BasicLSTMCell(num_units=n_neurons)\n",
    "              for layer in range(n_layers)]\n",
    "cell = tf.contrib.rnn.MultiRNNCell(lstm_cells)\n",
    "\n",
    "output_seqs, states = tf.contrib.legacy_seq2seq.embedding_rnn_seq2seq(\n",
    "    encoder_inputs,\n",
    "    decoder_inputs,\n",
    "    cell,\n",
    "    num_encoder_symbols,\n",
    "    num_decoder_symbols,\n",
    "    embedding_size)\n",
    "\n",
    "logits = tf.transpose(tf.unstack(output_seqs), perm=[1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "logits_flat = tf.reshape(logits, [-1, num_decoder_symbols])\n",
    "Y_target_flat = tf.reshape(Y_target, [-1])\n",
    "W_flat = tf.reshape(W, [-1])\n",
    "xentropy = W_flat * tf.nn.sparse_softmax_cross_entropy_with_logits(labels=Y_target_flat, logits=logits_flat)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nf] *",
   "language": "python",
   "name": "conda-env-nf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
